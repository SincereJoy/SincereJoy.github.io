
## 常用损失函数

|---
| 损失函数 | 公式 | 特点 
|:-:|:-:|:-:
| 0-1损失函数 | $L(y,f(\bm{x};\theta)) = I(y \neq f(\bm{x};\theta)), I为指示函数.$ | 直观，但不连续，导数为0，难以优化
| 平方损失函数 | $L(y,f(\bm{x};\theta)) = \frac{1}{2}(y - f(\bm{x};\theta))^2.$ | 适合$y \in \R$且y连续的情况，不适用于分类问题
| 交叉熵损失函数 | $L(\bm{y},f(\bm{x};\theta) )= -\bm{y} log f(\bm{x};\theta) = - \sum_{c=1}^Cy_clog f_c(\bm{x};\theta).$ | 又称负对数似然函数（从$y$为one-hot向量时的公式不难看出），适用于分类问题（y为离散值）
| Hinge损失函数 | $L(y,f(\bm{x};\theta)) = \max (0,1-yf(\bm{x};\theta)) \equiv [1-yf(\bm{x};\theta)]_+$ | 适用于二分类问题，$y \in \{-1,+1\}$
|---

为什么平方损失函数不适用于分类问题？
{:.info}

损失函数是用来量化模型预测和真实标签之间的差异的。由于分类问题的标签是离散的，且标签之间距离没有实际的意义，无法反映不同类别之间的差异。比如对于一个手写数字三分类问题，类别标签为{1，2，3}，对于样本(x,1)，将其误分类为2和3的错误程度应该是一样的，但对应的平方损失函数值却不同，所以平方损失函数不适用于分类问题。
{:.info}

## 学习准则
### 经验风险最小化
### 结构风险最小化
### 最大似然估计
### 最大后验估计

## 优化算法
